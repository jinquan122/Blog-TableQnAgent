{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q&A Agent\n",
    "#### General Idea: \n",
    "I investigate the dataset and found that some of the transactions can up to hundred thousands. At the very begining, I'm thinking to implement a RAG and store the data into a vector data store. But unfortunately, hundred thousands of transactions would overwhelm the LLM maximum context length. \n",
    "\n",
    "After much brainstorming, the huge amount of data can only be handled in SQL before fetching to LLM. Hence, the general idea of the LLM implementation would be focusing on how to generate an accurate SQL query to answer the user question.\n",
    "\n",
    "The prompt engineering part would be using the combination of chain of thought and showing some examples. There are totally three prompts implemented in this project:\n",
    "1. structured_filter_prompt: To investigate if there is any area we need to apply WHERE syntax. \n",
    "2. init_sql_prompt: To generate SQL query to answer the questions.\n",
    "3. synthesizer prompt: To synthesize results and questions for a human understandable response.\n",
    "\n",
    "Groq - LLama 3 70b and gemini-pro are used in this project. After several testing, LLama 3 70b showed a better output of SQL query as compared to other model including CodeQwen 1.5 7b. \n",
    "\n",
    "Main implementation idea:\n",
    "Make sure all the important outputs are structured output so that we can consume the output in programamtical way.\n",
    "\n",
    "Future Improvements:\n",
    "- Introduce Agent into the LLM so that different tasks can be solve by different functions.\n",
    "- Fine tuning a small LM for specific tasks.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Key in your client id and question here: (Actual implementation will have client id captured automatically when client ask question from their accounts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "client_id = 6\n",
    "client_question = \"What is the amount I have spent on shopping in the last 10 months?\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Main LLM and Smart LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from genai.llms import groq_llm, main_llm\n",
    "\n",
    "smart_llm = groq_llm()\n",
    "llm = main_llm()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "## Load data into pandas dataframe\n",
    "df = pd.read_csv(\"./data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['clnt_id', 'bank_id', 'acc_id', 'txn_id', 'txn_date', 'desc', 'amt',\n",
       "       'cat', 'merchant'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Check column names\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "clnt_id          0\n",
       "bank_id          0\n",
       "acc_id           0\n",
       "txn_id           0\n",
       "txn_date         0\n",
       "desc             0\n",
       "amt              0\n",
       "cat              0\n",
       "merchant    124881\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Check if there are any null values in the dataset\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_preprocessing import DataPreprocessing\n",
    "data_prep = DataPreprocessing()\n",
    "\n",
    "df = data_prep.column_rename(df)\n",
    "df = data_prep.null_replace(df)\n",
    "df = data_prep.datetime_format(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Filter object from query for SQL generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Concatenate the client context and question.\n",
    "client_id_context = f\"My client_id is {client_id}. \"\n",
    "query = client_id_context + client_question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Filter only relevant data for the client to make sure client cannot access other data\n",
    "df = df[df['client_id']==client_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Generate a list of unique categories from the given DataFrame.\n",
    "category_list = df['category'].unique().tolist()\n",
    "\n",
    "## Generate a list of unique merchants from the given dataset.\n",
    "merchant_list = df['merchant'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from genai.chain import extract_structured_filter\n",
    "from genai.output_parser import structured_output_parser\n",
    "\n",
    "## Define outpur parser\n",
    "output_parser_llm = structured_output_parser()\n",
    "\n",
    "## Extract filter objects for SQL generation\n",
    "structured_object = extract_structured_filter(output_parser_llm, query, category_list, merchant_list, llm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validate if the filter object is a valid category or merchant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "## Validate filter object for SQL generation\n",
    "## If the result is False, we need to rerun the structured_object query again - meaning that the LLM generate its own items will cause empty result coming back\n",
    "def valid_filter_object(structured_object, object_list, object):\n",
    "    is_match = True\n",
    "    if len(structured_object[object]) > 0:\n",
    "        for item in structured_object[object]:\n",
    "            if item not in object_list:\n",
    "                is_match = False\n",
    "    return is_match\n",
    "\n",
    "is_cat_match = valid_filter_object(structured_object, category_list, 'category')\n",
    "is_merc_match = valid_filter_object(structured_object, merchant_list, 'merchant')\n",
    "\n",
    "is_match = is_cat_match and is_merc_match\n",
    "print(is_match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'category': ['Shops']}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Filter a dictionary to remove empty values\n",
    "## Prepare to include the filter object into the prompt for SQL generation\n",
    "filtered_structured_object = {key: value for key, value in structured_object.items() if value}\n",
    "filtered_structured_object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SQL generation - Groq LLama 3 70b\n",
    "#### LLama 3 70b has a better reasoning skills as compared to other models. Would like to use his reasonning skill to generate a SQL query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is the generated DuckDB SQL query based on the provided details:\n",
      "\n",
      "```\n",
      "SELECT SUM(amount) \n",
      "FROM df \n",
      "WHERE client_id = 6 \n",
      "AND category = 'Shops' \n",
      "AND transaction_date > '2023-06-25' \n",
      "AND transaction_date <= '2024-04-25';\n",
      "```\n",
      "\n",
      "This query filters the data based on the provided filter object, which includes the category 'Shops', and also applies the date range filter to get the transactions in the last 10 months.\n"
     ]
    }
   ],
   "source": [
    "from genai.prompts import init_sql_prompt\n",
    "\n",
    "## Use Gemini Pro to generate sql query\n",
    "sql_prompt = init_sql_prompt(filtered_structured_object, query)\n",
    "valid_response = smart_llm.invoke(sql_prompt)\n",
    "valid_sql = str(valid_response.content)\n",
    "print(valid_sql)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract SQL query from the response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " SELECT SUM(amount)  FROM df  WHERE client_id = 6  AND category = 'Shops'  AND transaction_date > '2023-06-25'  AND transaction_date <= '2024-04-25'; \n"
     ]
    }
   ],
   "source": [
    "## Response is not purely SQL, so further preprocessing is needed to extract SQL code from it.\n",
    "sql = llm.invoke(f\"Please extract only SQL code from the given response. Response: {valid_sql}\")\n",
    "sql = sql.replace(\"\\n\", \" \").replace(\"sql\", \"\").replace(\"`\", \"\").replace(\"duckdb\", \"\")\n",
    "print(sql)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make use of DuckDB to use SQL and obtain results as Pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sum(amount)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.84</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sum(amount)\n",
       "0        14.84"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import duckdb\n",
    "\n",
    "results = duckdb.sql(sql).df()\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Synthesize the question and results obtained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from genai.prompts import sythesizer_prompt\n",
    "\n",
    "final_prompt = sythesizer_prompt(filtered_structured_object, query, results)\n",
    "final_response = smart_llm.invoke(final_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Your answer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have spent $14.84 on shopping in the last 10 months.\n",
      "\n",
      "Filtered by category: Shops and merchant: Not specified.\n"
     ]
    }
   ],
   "source": [
    "print(final_response.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
